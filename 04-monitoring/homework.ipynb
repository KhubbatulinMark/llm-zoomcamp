{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1e6453e-5da6-4390-8449-725b2256ef42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8059625-c978-4c64-a1ad-487ad19bf01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_4_mini = pd.read_csv(\"../assets/04-monitoring/results-gpt4o-mini.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec9c8656-411a-4894-b76c-e2ff3b5f9ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_llm</th>\n",
       "      <th>answer_orig</th>\n",
       "      <th>document</th>\n",
       "      <th>question</th>\n",
       "      <th>course</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You can sign up for the course by visiting the...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Where can I sign up for the course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You can sign up using the link provided in the...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Can you provide a link to sign up?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes, there is an FAQ for the Machine Learning ...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Is there an FAQ for this Machine Learning course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          answer_llm  \\\n",
       "0  You can sign up for the course by visiting the...   \n",
       "1  You can sign up using the link provided in the...   \n",
       "2  Yes, there is an FAQ for the Machine Learning ...   \n",
       "\n",
       "                                         answer_orig  document  \\\n",
       "0  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "1  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "2  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "\n",
       "                                            question  \\\n",
       "0                Where can I sign up for the course?   \n",
       "1                 Can you provide a link to sign up?   \n",
       "2  Is there an FAQ for this Machine Learning course?   \n",
       "\n",
       "                      course  \n",
       "0  machine-learning-zoomcamp  \n",
       "1  machine-learning-zoomcamp  \n",
       "2  machine-learning-zoomcamp  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_4_mini.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bf928e-cb13-4f9c-837b-0d14631889e9",
   "metadata": {},
   "source": [
    "**We will use only the first 300 documents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68965da2-4bd4-459f-a25c-cbd0cec23e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_4_mini = gpt_4_mini.iloc[:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d66471-c45c-4db3-9cde-3342a1744946",
   "metadata": {},
   "source": [
    "# Q1. Getting the embeddings model\n",
    "Now, get the embeddings model *multi-qa-mpnet-base-dot-v1* from the [Sentence Transformer library](https://www.sbert.net/docs/sentence_transformer/pretrained_models.html#model-overview).\n",
    "\n",
    "Create the embeddings for the first LLM answer:\n",
    "\n",
    "`answer_llm = df.iloc[0].answer_llm`\n",
    "\n",
    "What's the first value of the resulting vector?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20a656ae-a492-4aa3-9ae4-567bf46c1935",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b85898c-7716-4788-966b-6b608d8e1651",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You try to use a model that was created with version 3.0.0.dev0, however, your version is 2.7.0. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
      "\n",
      "\n",
      "\n",
      "/usr/local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embedding_model = SentenceTransformer(\"multi-qa-mpnet-base-dot-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d73be5ab-7832-4f59-9a60-9e50fc077bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You can sign up for the course by visiting the course page at [http://mlzoomcamp.com/](http://mlzoomcamp.com/).'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_llm = gpt_4_mini.iloc[0].answer_llm\n",
    "answer_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f656857-adae-4cf0-beb0-e9cea95b1bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = embedding_model.encode(answer_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6648d84c-7987-4f3a-aa6c-aa9f554b8b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.4224469"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1c6ac6-aa38-46bc-b511-d6fdbeaae1d3",
   "metadata": {},
   "source": [
    "# Q2. Computing the dot product\n",
    "Now for each answer pair, let's create embeddings and compute dot product between them\n",
    "\n",
    "We will put the results (scores) into the evaluations list\n",
    "\n",
    "What's the 75% percentile of the score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e23c9267-b783-4292-a94e-1b64900925e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "608629e5-161b-402f-bb7b-699fbb2f9eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity(model, record):\n",
    "    answer_orig = record['answer_orig']\n",
    "    answer_llm = record['answer_llm']\n",
    "    \n",
    "    v_llm = model.encode(answer_llm)\n",
    "    v_orig = model.encode(answer_orig)\n",
    "    \n",
    "    return v_llm.dot(v_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bbfc3dd-840a-4ad6-a378-1710ccb6f559",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [01:31<00:00,  3.26it/s]\n"
     ]
    }
   ],
   "source": [
    "evaluations = []\n",
    "gpt_4_mini_iter = gpt_4_mini.to_dict(orient='records')\n",
    "for record in tqdm(gpt_4_mini_iter):\n",
    "    sim = compute_similarity(embedding_model, record)\n",
    "    evaluations.append(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59e02cfc-3bde-4676-a8a9-e26fdc041cb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gpt_4_mini['cosine'] = evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe913ce9-aa76-48e8-94cd-41aaf2783280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.674306869506836"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_4_mini['cosine'].describe().loc[\"75%\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f256540f-da9e-45af-8af5-9775e46c75f3",
   "metadata": {},
   "source": [
    "# Q3. Computing the cosine\n",
    "From Q2, we can see that the results are not within the [0, 1] range. It's because the vectors coming from this model are not normalized.\n",
    "\n",
    "So we need to normalize them.\n",
    "\n",
    "To do it, we\n",
    "\n",
    "Compute the norm of a vector\n",
    "Divide each element by this norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dba668e3-f2dd-40c3-bc55-02aa80f135a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7a3766f-5808-4c15-af8e-c6e06b5108bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(vector):\n",
    "    norm = np.sqrt((vector * vector).sum())\n",
    "    return vector / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21dfbbe9-da52-448a-9b81-9131de8bff04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_normalize_similarity(model, record):\n",
    "    answer_orig = record['answer_orig']\n",
    "    answer_llm = record['answer_llm']\n",
    "    \n",
    "    v_llm = normalize(model.encode(answer_llm))\n",
    "    v_orig = normalize(model.encode(answer_orig))\n",
    "    \n",
    "    return v_llm.dot(v_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b78daad5-d987-4caa-bb5e-1e4da0366914",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [01:51<00:00,  2.68it/s]\n"
     ]
    }
   ],
   "source": [
    "evaluations_normalize = []\n",
    "gpt_4_mini_iter = gpt_4_mini.to_dict(orient='records')\n",
    "for record in tqdm(gpt_4_mini_iter):\n",
    "    sim = compute_normalize_similarity(embedding_model, record)\n",
    "    evaluations_normalize.append(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c99c524-1bc1-4e95-a50f-c290813fabf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_4_mini['cosine_norm'] = evaluations_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc165028-4c66-45e4-a772-c27c25f40614",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8362348228693008"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_4_mini['cosine_norm'].describe()[\"75%\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d939257-4e69-49b1-96a1-884ad3cb71f1",
   "metadata": {},
   "source": [
    "# Q4. Rouge\n",
    "Now we will explore an alternative metric - the ROUGE score.\n",
    "\n",
    "This is a set of metrics that compares two answers based on the overlap of n-grams, word sequences, and word pairs.\n",
    "\n",
    "It can give a more nuanced view of text similarity than just cosine similarity alone.\n",
    "\n",
    "Let's compute the ROUGE score between the answers at the index 10 of our dataframe (doc_id=5170565b)\n",
    "\n",
    "There are three scores: `rouge-1`, `rouge-2` and `rouge-l`, and precision, recall and F1 score for each.\n",
    "\n",
    "* `rouge-1` - the overlap of unigrams,\n",
    "* `rouge-2` - bigrams,\n",
    "* `rouge-l` - the longest common subsequence\n",
    "  \n",
    "What's the F score for `rouge-1`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a40e672-2273-4762-ab48-6989e4deed7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c1f251b-e09e-4933-9297-da96374aec42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_llm</th>\n",
       "      <th>answer_orig</th>\n",
       "      <th>document</th>\n",
       "      <th>question</th>\n",
       "      <th>course</th>\n",
       "      <th>cosine</th>\n",
       "      <th>cosine_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Yes, all sessions are recorded, so if you miss...</td>\n",
       "      <td>Everything is recorded, so you won’t miss anyt...</td>\n",
       "      <td>5170565b</td>\n",
       "      <td>Are sessions recorded if I miss one?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>32.344715</td>\n",
       "      <td>0.777956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Yes, you can ask your questions in advance if ...</td>\n",
       "      <td>Everything is recorded, so you won’t miss anyt...</td>\n",
       "      <td>5170565b</td>\n",
       "      <td>Can I ask questions in advance if I can't atte...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>31.441849</td>\n",
       "      <td>0.783566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>If you miss a session, don't worry! Everything...</td>\n",
       "      <td>Everything is recorded, so you won’t miss anyt...</td>\n",
       "      <td>5170565b</td>\n",
       "      <td>How will my questions be addressed if I miss a...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>36.380722</td>\n",
       "      <td>0.904688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Yes, there is a way to catch up on a missed se...</td>\n",
       "      <td>Everything is recorded, so you won’t miss anyt...</td>\n",
       "      <td>5170565b</td>\n",
       "      <td>Is there a way to catch up on a missed session?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>33.340508</td>\n",
       "      <td>0.806303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Yes, you can still interact with instructors a...</td>\n",
       "      <td>Everything is recorded, so you won’t miss anyt...</td>\n",
       "      <td>5170565b</td>\n",
       "      <td>Can I still interact with instructors after mi...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>30.606157</td>\n",
       "      <td>0.727596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           answer_llm  \\\n",
       "10  Yes, all sessions are recorded, so if you miss...   \n",
       "11  Yes, you can ask your questions in advance if ...   \n",
       "12  If you miss a session, don't worry! Everything...   \n",
       "13  Yes, there is a way to catch up on a missed se...   \n",
       "14  Yes, you can still interact with instructors a...   \n",
       "\n",
       "                                          answer_orig  document  \\\n",
       "10  Everything is recorded, so you won’t miss anyt...  5170565b   \n",
       "11  Everything is recorded, so you won’t miss anyt...  5170565b   \n",
       "12  Everything is recorded, so you won’t miss anyt...  5170565b   \n",
       "13  Everything is recorded, so you won’t miss anyt...  5170565b   \n",
       "14  Everything is recorded, so you won’t miss anyt...  5170565b   \n",
       "\n",
       "                                             question  \\\n",
       "10               Are sessions recorded if I miss one?   \n",
       "11  Can I ask questions in advance if I can't atte...   \n",
       "12  How will my questions be addressed if I miss a...   \n",
       "13    Is there a way to catch up on a missed session?   \n",
       "14  Can I still interact with instructors after mi...   \n",
       "\n",
       "                       course     cosine  cosine_norm  \n",
       "10  machine-learning-zoomcamp  32.344715     0.777956  \n",
       "11  machine-learning-zoomcamp  31.441849     0.783566  \n",
       "12  machine-learning-zoomcamp  36.380722     0.904688  \n",
       "13  machine-learning-zoomcamp  33.340508     0.806303  \n",
       "14  machine-learning-zoomcamp  30.606157     0.727596  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_4_mini[gpt_4_mini[\"document\"] == \"5170565b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa004313-0431-40b8-8648-cdfa333124d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_10 = gpt_4_mini.iloc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f8b1838-10a8-4231-bc77-cc09dccadb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_scorer = Rouge()\n",
    "scores = rouge_scorer.get_scores(record_10['answer_llm'], record_10['answer_orig'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe8acc93-f44b-4c93-9ddb-3cdb19bb90d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.45454545454545453,\n",
       "  'p': 0.45454545454545453,\n",
       "  'f': 0.45454544954545456},\n",
       " 'rouge-2': {'r': 0.21621621621621623,\n",
       "  'p': 0.21621621621621623,\n",
       "  'f': 0.21621621121621637},\n",
       " 'rouge-l': {'r': 0.3939393939393939,\n",
       "  'p': 0.3939393939393939,\n",
       "  'f': 0.393939388939394}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "997011a2-8521-4fa5-a727-c07f9ce7771b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45454544954545456"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[\"rouge-1\"][\"f\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4767d7-077a-41f5-bf4b-8ad72b5471fc",
   "metadata": {},
   "source": [
    "# Q5. Average rouge score\n",
    "Let's compute the average F-score between `rouge-1`, `rouge-2` and `rouge-l` for the same record from Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9dab0048-0873-4326-a4ed-5a1501a0fc59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35490034990035496"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray([metrics[\"f\"] for metrics in scores.values()]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0739bfb3-fceb-468f-8cdb-24e5de9df2cf",
   "metadata": {},
   "source": [
    "# Q6. Average rouge score for all the data points\n",
    "Now let's compute the score for all the records and create a dataframe from them.\n",
    "\n",
    "What's the average rouge_2 across all the records?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc79c293-5f16-4bc5-9196-916c567974df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rouge(rouge_scorer, record, score=\"rouge-2\", metric=\"f\"):\n",
    "    answer_orig = record['answer_orig']\n",
    "    answer_llm = record['answer_llm']\n",
    "\n",
    "    scores = rouge_scorer.get_scores(answer_llm, answer_orig)[0]\n",
    "    return scores[score][metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "608617dd-8132-4913-9bf0-b4fd500b9a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:00<00:00, 552.54it/s]\n"
     ]
    }
   ],
   "source": [
    "f1_rouge_2_scores = []\n",
    "gpt_4_mini_iter = gpt_4_mini.to_dict(orient='records')\n",
    "for record in tqdm(gpt_4_mini_iter):\n",
    "    score = compute_rouge(rouge_scorer, record, score=\"rouge-2\", metric=\"f\")\n",
    "    f1_rouge_2_scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f805a298-ff71-42a2-ae95-f99e175408ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20696501983423318"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(f1_rouge_2_scores).mean() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
